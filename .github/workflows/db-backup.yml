name: Render PostgreSQL Backup

on:
  schedule:
    - cron: "0 2 * * *"
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client postgresql-common

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib

      - name: Create database dump
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          set -e
          TS=$(date -u +"%Y%m%d-%H%M%S")
          NAME="render-postgres-backup-${TS}.dump.gz"
          
          echo "DATABASE_URL format: ${DATABASE_URL:0:50}..."
          
          # Extract connection info from DATABASE_URL using Python
          python3 << 'EOF' > conn_info.txt
import os
import re
db_url = os.environ.get('DATABASE_URL', '')
# Parse postgresql://user:pass@host:port/db
match = re.match(r'postgresql://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)', db_url)
if match:
    user, password, host, port, dbname = match.groups()
    print(f"DB_HOST={host}")
    print(f"DB_PORT={port}")
    print(f"DB_NAME={dbname}")
    print(f"DB_USER={user}")
    print(f"DB_PASS={password}")
else:
    print("Failed to parse DATABASE_URL")
    print(f"URL: {db_url}")
EOF
          
          # Source the connection info
          cat conn_info.txt
          source conn_info.txt
          
          echo "Creating database dump using PostgreSQL 18 Docker..."
          echo "Host: $DB_HOST, Port: $DB_PORT, User: $DB_USER, DB: $DB_NAME"
          
          # Use Docker with PostgreSQL 18 and force TCP connection
          docker run --rm \
            -e PGPASSWORD="$DB_PASS" \
            postgres:18 \
            pg_dump -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" \
            --no-owner --no-privileges --format=custom \
            --host="$DB_HOST" --port="$DB_PORT" "$DB_NAME" | gzip -c > "$NAME"
          
          echo "BACKUP_FILE=$NAME" >> $GITHUB_ENV
          echo "BACKUP_PREFIX=render-postgres-backup-" >> $GITHUB_ENV
          echo "Backup file size: $(stat -c%s "$NAME" || echo 'unknown')"

      - name: Upload to Google Drive + retention
        env:
          GDRIVE_CLIENT_SECRET_JSON: ${{ secrets.GDRIVE_CLIENT_SECRET_JSON }}
          GDRIVE_REFRESH_TOKEN: ${{ secrets.GDRIVE_REFRESH_TOKEN }}
          GDRIVE_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
        run: |
          python tools/drive_backup_oauth.py --file "$BACKUP_FILE" --name "$BACKUP_FILE" --prefix "$BACKUP_PREFIX" --keep-last 30
